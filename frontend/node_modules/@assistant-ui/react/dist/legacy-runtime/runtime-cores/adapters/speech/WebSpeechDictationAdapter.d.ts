import type { DictationAdapter } from "./SpeechAdapterTypes.js";
interface SpeechRecognitionInstance extends EventTarget {
    lang: string;
    continuous: boolean;
    interimResults: boolean;
    start(): void;
    stop(): void;
    abort(): void;
}
interface SpeechRecognitionConstructor {
    new (): SpeechRecognitionInstance;
}
declare global {
    interface Window {
        SpeechRecognition?: SpeechRecognitionConstructor;
        webkitSpeechRecognition?: SpeechRecognitionConstructor;
    }
}
/**
 * WebSpeechDictationAdapter provides speech-to-text (dictation) functionality using
 * the browser's Web Speech API (SpeechRecognition).
 *
 * @example
 * ```tsx
 * const runtime = useChatRuntime({
 *   api: "/api/chat",
 *   adapters: {
 *     dictation: new WebSpeechDictationAdapter(),
 *   },
 * });
 * ```
 */
export declare class WebSpeechDictationAdapter implements DictationAdapter {
    private _language;
    private _continuous;
    private _interimResults;
    constructor(options?: {
        /**
         * The language for dictation (e.g., "en-US", "zh-CN").
         * Defaults to the browser's language.
         */
        language?: string;
        /**
         * Whether to keep recording after the user stops speaking.
         * Defaults to true.
         */
        continuous?: boolean;
        /**
         * Whether to return interim (partial) results.
         * Defaults to true for real-time feedback.
         */
        interimResults?: boolean;
    });
    /**
     * Check if the browser supports the Web Speech Recognition API.
     */
    static isSupported(): boolean;
    listen(): DictationAdapter.Session;
}
export {};
//# sourceMappingURL=WebSpeechDictationAdapter.d.ts.map